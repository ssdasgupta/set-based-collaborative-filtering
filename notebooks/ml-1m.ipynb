{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "seed = 123\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from .dat file\n",
    "data_path = '../data/ml-1m/ratings.dat'\n",
    "ratings = pd.read_csv(data_path, sep='::', header=None, engine='python', names=['userId', 'movieId', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_count = {}\n",
    "for userID, movieID, rating in zip(ratings['userId'], ratings['movieId'], ratings['rating']):\n",
    "    user_id_count[userID] = user_id_count.get(userID, 0) + 1\n",
    "user_reject_list = [userID for userID, count in user_id_count.items() if count < 20]\n",
    "ratings = ratings[~ratings['userId'].isin(user_reject_list)]\n",
    "\n",
    "movie_id_count = {}\n",
    "for userID, movieID, rating in zip(ratings['userId'], ratings['movieId'], ratings['rating']):\n",
    "    movie_id_count[movieID] = movie_id_count.get(movieID, 0) + 1\n",
    "\n",
    "count_10_movies = [movieID for movieID, count in movie_id_count.items() if count < 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-id data and vocab creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2idx = {userID: i for i, userID in enumerate(ratings['userId'].unique())}\n",
    "movie2idx = {movieID: i for i, movieID in enumerate(ratings['movieId'].unique())}\n",
    "idx2movie = {i: movieID for i, movieID in enumerate(ratings['movieId'].unique())}\n",
    "ratings['userId'] = ratings['userId'].map(user2idx)\n",
    "ratings['movieId'] = ratings['movieId'].map(movie2idx)\n",
    "count_10_movies = [movie2idx[movieID] for movieID in count_10_movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 6040\n",
      "Number of movies: 3706\n",
      "Number of ratings: 1000209\n"
     ]
    }
   ],
   "source": [
    "print('Number of users:', len(user2idx))\n",
    "print('Number of movies:', len(movie2idx))\n",
    "print('Number of ratings:', len(ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adj matrix with time-stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_rating_matrix_dict = {}\n",
    "movieid_set = set()\n",
    "for userID, movieID, rating, timestamp in zip(ratings['userId'], ratings['movieId'], ratings['rating'], ratings['timestamp']):\n",
    "    if userID not in implicit_rating_matrix_dict:\n",
    "        implicit_rating_matrix_dict[userID] = [(movieID, timestamp)]\n",
    "    else:\n",
    "        implicit_rating_matrix_dict[userID].append((movieID, timestamp))\n",
    "    movieid_set.add(movieID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 6040\n",
      "Number of movies: 3706\n"
     ]
    }
   ],
   "source": [
    "print('Number of users:', len(implicit_rating_matrix_dict))\n",
    "print('Number of movies:', len(movieid_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test / Val / Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = []\n",
    "item_train_list = []\n",
    "item_test_list = []\n",
    "item_valid_list = []\n",
    "item_gt_list = []\n",
    "for userID, movieID_timestamp_list in implicit_rating_matrix_dict.items():\n",
    "    movieID_timestamp_list = sorted(movieID_timestamp_list, key=lambda x: x[1])\n",
    "    movieID_list = [movieID for movieID, timestamp in movieID_timestamp_list]\n",
    "    item_gt_list.append(movieID_list)\n",
    "    user_list.append(userID)\n",
    "    item_train_list.append(movieID_list[:-2])\n",
    "    item_valid_list.append(movieID_list[-2])\n",
    "    item_test_list.append(movieID_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency2df(user_list, item_list_of_list):\n",
    "    user = []\n",
    "    item = []\n",
    "    for i in range(len(user_list)):\n",
    "        user.extend([user_list[i]] * len(item_list_of_list[i]))\n",
    "        item.extend(item_list_of_list[i])\n",
    "    return pd.DataFrame({'userId': user, 'movieId': item})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency2df(user_list, item_train_list).to_csv('../data/ml-1m/train.csv', index=False)\n",
    "adjacency2df(user_list, item_gt_list).to_csv('../data/ml-1m/gt.csv', index=False)\n",
    "pd.DataFrame({'userId': user_list, 'movieId': item_valid_list}).to_csv('../data/ml-1m/val.csv', index=False)\n",
    "pd.DataFrame({'userId': user_list, 'movieId': item_test_list}).to_csv('../data/ml-1m/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2id_df = pd.DataFrame({'original_userId': list(user2idx.keys()), 'userId': list(user2idx.values())})\n",
    "movie2id_df = pd.DataFrame({'original_movieId': list(movie2idx.keys()), 'movieId': list(movie2idx.values())})\n",
    "user2id_df.to_csv(f'../data/ml-1m/user2id.csv', index=False)\n",
    "movie2id_df.to_csv(f'../data/ml-1m/movie2id.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate negative samples for valid and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hundred_negatives(item_train_list, item_valid_list, item_test_list, user_list, movie2idx):\n",
    "    val_list = []\n",
    "    test_list = []\n",
    "    for i, userID in enumerate(user_list):\n",
    "        exclude_list = item_train_list[i] + [item_valid_list[i]] + [item_test_list[i]]\n",
    "        negative_sample_init = random.sample(range(len(movie2idx)), 500)\n",
    "        for ele in exclude_list:\n",
    "            if ele in negative_sample_init:\n",
    "                negative_sample_init.remove(ele)\n",
    "        if len(negative_sample_init) > 200:\n",
    "            val_negative_sample = negative_sample_init[:100]\n",
    "            test_negative_sample = negative_sample_init[100:200]\n",
    "        else:\n",
    "            print(\"need to resample\")\n",
    "            continue\n",
    "        val_list.append(val_negative_sample + [item_valid_list[i]])\n",
    "        test_list.append(test_negative_sample + [item_test_list[i]])\n",
    "    return val_list, test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list, test_list = get_hundred_negatives(item_train_list, item_valid_list, item_test_list, user_list, movie2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dict = lambda x, y: {y[i]: x[i] for i in range(len(x))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dict = get_dict(val_list, user_list)\n",
    "test_dict = get_dict(test_list, user_list)\n",
    "# dict to dataframe\n",
    "val_df = pd.DataFrame(val_dict).to_csv('../data/ml-1m/val_101.csv', index=False)\n",
    "test_df = pd.DataFrame(test_dict).to_csv('../data/ml-1m/test_101.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate Pipe for Generating negative samples for valid and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = []\n",
    "item_train_list = []\n",
    "item_valid_list = []\n",
    "item_gt_list = []\n",
    "for userID, movieID_timestamp_list in implicit_rating_matrix_dict.items():\n",
    "    movieID_timestamp_list = sorted(movieID_timestamp_list, key=lambda x: x[1])\n",
    "    movieID_list = [movieID for movieID, timestamp in movieID_timestamp_list]\n",
    "    item_gt_list.append(movieID_list)\n",
    "    user_list.append(userID)\n",
    "    item_train_list.append(movieID_list[:-1])\n",
    "    item_valid_list.append(movieID_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency2df(user_list, item_list_of_list):\n",
    "    user = []\n",
    "    item = []\n",
    "    for i in range(len(user_list)):\n",
    "        user.extend([user_list[i]] * len(item_list_of_list[i]))\n",
    "        item.extend(item_list_of_list[i])\n",
    "    return pd.DataFrame({'userId': user, 'movieId': item})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency2df(user_list, item_train_list).to_csv('../data/ml-1m/train.csv', index=False)\n",
    "adjacency2df(user_list, item_gt_list).to_csv('../data/ml-1m/gt.csv', index=False)\n",
    "pd.DataFrame({'userId': user_list, 'movieId': item_valid_list}).to_csv('../data/ml-1m/val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2id_df = pd.DataFrame({'original_userId': list(user2idx.keys()), 'userId': list(user2idx.values())})\n",
    "movie2id_df = pd.DataFrame({'original_movieId': list(movie2idx.keys()), 'movieId': list(movie2idx.values())})\n",
    "user2id_df.to_csv(f'../data/ml-1m/user2id.csv', index=False)\n",
    "movie2id_df.to_csv(f'../data/ml-1m/movie2id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hundred_negatives(item_train_list, item_valid_list, user_list, movie2idx):\n",
    "    val_list = []\n",
    "    for i, userID in enumerate(user_list):\n",
    "        exclude_list = item_train_list[i] + [item_valid_list[i]]\n",
    "        negative_sample_init = random.sample(range(len(movie2idx)), 300)\n",
    "        for ele in exclude_list:\n",
    "            if ele in negative_sample_init:\n",
    "                negative_sample_init.remove(ele)\n",
    "        if len(negative_sample_init) > 100:\n",
    "            val_negative_sample = negative_sample_init[:100]\n",
    "        else:\n",
    "            print(\"need to resample\")\n",
    "            continue\n",
    "        val_list.append(val_negative_sample + [item_valid_list[i]])\n",
    "    return val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list = get_hundred_negatives(item_train_list, item_valid_list, user_list, movie2idx)\n",
    "get_dict = lambda x, y: {y[i]: x[i] for i in range(len(x))}\n",
    "val_dict = get_dict(val_list, user_list)\n",
    "# dict to dataframe\n",
    "val_df = pd.DataFrame(val_dict).to_csv('../data/ml-1m/val_101.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boxrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
