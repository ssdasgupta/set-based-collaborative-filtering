{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the prototype of a Collaborative Filtering Model development, Evaluation, and data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = 10000\n",
    "num_users = 10000\n",
    "\n",
    "# Generate random data for item user interactions where each user has about 100 to 10 items rated\n",
    "# and each item has about 100 to 10 users rating it.\n",
    "# The ratings are generated randomly between 0 and 5.\n",
    "def generate_data():\n",
    "    data = np.zeros((num_items, num_users))\n",
    "    for i in range(num_items):\n",
    "        for j in range(num_users):\n",
    "            if np.random.randint(0, 100) < 10:\n",
    "                data[i][j] = np.random.randint(0, 5)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = generate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Box Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the TEM paper datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each user split the data into training and test data\n",
    "# split should be 80% of the rated movies to the training set and 20% of the rated movies to the test set.\n",
    "def split_data(dataset):\n",
    "    train = np.zeros((num_items, num_users))\n",
    "    test = np.zeros((num_items, num_users))\n",
    "    for i in range(num_users):\n",
    "        rated_items = np.nonzero(dataset[:,i])[0]\n",
    "        train_items = np.random.choice(rated_items, int(len(rated_items) * 0.8))\n",
    "        test_items = np.setdiff1d(rated_items, train_items)\n",
    "        train[train_items,i] = dataset[train_items,i]\n",
    "        test[test_items,i] = dataset[test_items,i]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_data(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement matrix factorization for collaborative filtering using stochastic gradient descent.\n",
    "# Use the training data to learn the matrix factorization.\n",
    "# Use the test data to evaluate the performance of your algorithm.\n",
    "# You can use the following parameters for your algorithm:\n",
    "# Number of factors: 10\n",
    "# Learning rate: 0.01\n",
    "# Number of epochs: 10\n",
    "# You can use the following evaluation metric:\n",
    "# Mean absolute error (MAE): mean(|predicted_rating - actual_rating|)\n",
    "# The lower the MAE the better.\n",
    "# You can use the following reference to implement matrix factorization:\n",
    "# https://medium.com/@jdwittenauer/deep-learning-with-keras-recommender-systems-e7b99cb29929\n",
    "\n",
    "\n",
    "class MatrixFactorization:\n",
    "    def __init__(self, num_factors, learning_rate, num_epochs):\n",
    "        self.num_factors = num_factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.user_embeddings = nn.Embedding(num_users, num_factors)\n",
    "    \n",
    "    def fit(self, train):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
